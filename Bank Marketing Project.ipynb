{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91ace844",
   "metadata": {},
   "source": [
    "# Bank Marketing Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05051b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing requierd libraries\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from prettytable import PrettyTable\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import log_loss\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c0c930",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('bank-full.csv', sep=';')\n",
    "print('Shape of our data {}'.format(data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d5f687",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4cf40b4a",
   "metadata": {},
   "source": [
    "Dataset Description\n",
    "\n",
    "The data is related with direct marketing campaigns of a Portuguese banking institution. The marketing campaigns were based on phone calls. Often, more than one contact to the same client was required, in order to access if the product (bank term deposit) would be (or not) subscribed.\n",
    "Attribute/Features Description:\n",
    "Dataset have 17 attributes including one dependent attribute and there are 45211 instances/datapoints. So we have 16 predictor/independent attributes and 1 dependent attribute.\n",
    "\n",
    "bank client attributes:\n",
    "\n",
    "-age: age of client (numeric)\n",
    "-job : type of job (categorical: \"admin.\", \"unknown\", \"unemployed\", \"management\", \"housemaid\", \"entrepreneur\", \"student\", \"blue-collar\", \"self-employed\", \"retired\", \"technician\", \"services\")\n",
    "-marital : marital status (categorical: \"married\", \"divorced\", \"single\")\n",
    "-education: client highest education (categorical: \"unknown\", \"secondary\", \"primary\", \"tertiary\")\n",
    "-default: has credit in default? (binary/2-categories: \"yes\", \"no\")\n",
    "-balance: average yearly balance, in euros (numeric)\n",
    "-housing: has housing loan? (binary/2-categories: \"yes\", \"no\")\n",
    "-loan: has personal loan? (binary/2-categories: \"yes\", \"no\")\n",
    "\n",
    "related with the last contact of the current campaign:\n",
    "-contact: contact communication type (categorical: \"unknown\", \"telephone\", \"cellular\")\n",
    "-day: last contact day of the month (numeric)\n",
    "-month: last contact month of year (categorical: \"jan\", \"feb\", \"mar\", ..., \"nov\", \"dec\")\n",
    "-duration: last contact duration, in seconds (numeric)\n",
    "\n",
    "other attributes:\n",
    "-campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)\n",
    "-pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric, -1 means client was not previously contacted)\n",
    "-previous: number of contacts performed before this campaign and for this client (numeric)\n",
    "-poutcome: outcome of the previous marketing campaign ( categorical: 'unknown\",\"other\", \"failure\", \"success\")\n",
    "\n",
    "Output variable (desired target):\n",
    "-y: has the client subscribed a term deposit? (binary: \"yes\", \"no\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293d3c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d724bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300b1203",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome']\n",
    "numerical = [x for x in data.columns.to_list() if x not in categorical]\n",
    "numerical.remove('y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f99a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Categorical features:', categorical)\n",
    "print('Numerical features:', numerical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e53847",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "sns.countplot(x=data['y'])\n",
    "plt.title('Distribution of classes')\n",
    "plt.xlabel('Target class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15dc29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2224269",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(y=data['pdays'], x=data['y'])\n",
    "plt.title('Box plot of pdays vs y (target variable)')\n",
    "plt.xlabel('y: target variable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fadfb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.FacetGrid(data, hue='y', size=5) \\\n",
    ".map(sns.distplot, 'pdays') \\\n",
    ".add_legend()\n",
    "plt.title('PDF of pdays for target variable y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a9782d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.pdays.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb995d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(95, 101 , 1):\n",
    "    print(\"{}% of pdays are less than equal to {}\".format(x, data.pdays.quantile(x/100)))\n",
    "iqr = data.pdays.quantile(0.75) - data.pdays.quantile(0.25)\n",
    "print('IQR {}'.format(iqr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82868a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting call duration from seconds to minute\n",
    "data['duration'] = data['duration']/60\n",
    "sns.boxplot(y=data['duration'], x=data['y'])\n",
    "plt.title('Box plot of duration vs y(target variable)')\n",
    "plt.xlabel('y:target variable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc0edc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.FacetGrid(data, hue='y', size=5) \\\n",
    ".map(sns.distplot, 'duration') \\\n",
    ".add_legend()\n",
    "plt.title('PDF of duration for target variable y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916ed102",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.duration.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60dbb101",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(95, 101 , 1):\n",
    "    print(\"{}% of calls have duration less than equal to {}\".format(x, data.duration.quantile(x/100)))\n",
    "iqr = data.duration.quantile(0.75) - data.duration.quantile(0.25)\n",
    "print('IQR {}'.format(iqr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6811a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(y=data['previous'], x=data['y'])\n",
    "plt.title('Box plot of previous vs y(target variable)')\n",
    "plt.xlabel('y:target variable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84aa178",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.FacetGrid(data, hue='y', size=5) \\\n",
    ".map(sns.distplot, 'previous') \\\n",
    ".add_legend()\n",
    "plt.title('PDF of previous values for target variable y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e24b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.previous.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921041b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(95, 101 , 1):\n",
    "    print(\"{}% of previous values less than equal to {}\".format(x, data.previous.quantile(x/100)))\n",
    "iqr = data.previous.quantile(0.75) - data.previous.quantile(0.25)\n",
    "print('IQR {}'.format(iqr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fca0da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(y=data['age'], x=data['y'])\n",
    "plt.title('Box plot of age vs y(target variable)')\n",
    "plt.xlabel('y:target variable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811917ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.FacetGrid(data, hue='y', size=5) \\\n",
    ".map(sns.distplot, 'age') \\\n",
    ".add_legend()\n",
    "plt.title('PDF of age for target variable y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643b21e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.age.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d011a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(95, 101 , 1):\n",
    "    print(\"{}% of people having age are less than equal to {}\".format(x, data.age.quantile(x/100)))\n",
    "iqr = data.age.quantile(0.75) - data.age.quantile(0.25)\n",
    "print('IQR {}'.format(iqr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee8e9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [data]\n",
    "for column in lst:\n",
    "    column.loc[column[\"age\"] < 30,  'age_group'] = 30\n",
    "    column.loc[(column[\"age\"] >= 30) & (column[\"age\"] <= 44), 'age_group'] = 40\n",
    "    column.loc[(column[\"age\"] >= 45) & (column[\"age\"] <= 59), 'age_group'] = 50\n",
    "    column.loc[column[\"age\"] >= 60, 'age_group'] = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7501ddaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_age_response_pct = pd.crosstab(data['y'],data['age_group']).apply(lambda x: x/x.sum() * 100)\n",
    "count_age_response_pct = count_age_response_pct.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2186a9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='age_group', data=data, hue='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a63d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Success rate and total clients contacted for different age_groups:')\n",
    "print('Clients age < 30 contacted: {}, Success rate: {}'.format(len(data[data['age_group'] == 30]), data[data['age_group'] == 30].y.value_counts()[1]/len(data[data['age_group'] == 30])))\n",
    "print('Clients of age 30-45 contacted: {}, Success rate: {}'.format(len(data[data['age_group'] == 40]), data[data['age_group'] == 40].y.value_counts()[1]/len(data[data['age_group'] == 40])))\n",
    "print('Clients of age 40-60 contacted: {}, Success rate: {}'.format(len(data[data['age_group'] == 50]), data[data['age_group'] == 50].y.value_counts()[1]/len(data[data['age_group'] == 50])))\n",
    "print('Clients of 60+ age contacted: {}, Success rate: {}'.format(len(data[data['age_group'] == 60]), data[data['age_group'] == 60].y.value_counts()[1]/len(data[data['age_group'] == 60])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb96feea",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.job.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14f1881",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(20,6)})\n",
    "sns.countplot(x=data['job'], data=data, hue=data['y'])\n",
    "plt.title('Count Plot of job for target variable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f2f20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = PrettyTable(['Job', 'Total Clients', 'Success rate'])\n",
    "table.add_row(['Blue-collar', len(data[data['job'] == 'blue-collar']), data[data['job'] == 'blue-collar'].y.value_counts()[1]/len(data[data['job'] == 'blue-collar'])])\n",
    "table.add_row(['Management', len(data[data['job'] == 'management']), data[data['job'] == 'management'].y.value_counts()[1]/len(data[data['job'] == 'management'])])\n",
    "table.add_row(['Technician', len(data[data['job'] == 'technician']), data[data['job'] == 'technician'].y.value_counts()[1]/len(data[data['job'] == 'technician'])])\n",
    "table.add_row(['Admin', len(data[data['job'] == 'admin.']), data[data['job'] == 'admin.'].y.value_counts()[1]/len(data[data['job'] == 'admin.'])])\n",
    "table.add_row(['Services', len(data[data['job'] == 'services']), data[data['job'] == 'services'].y.value_counts()[1]/len(data[data['job'] == 'services'])])\n",
    "table.add_row(['Retired', len(data[data['job'] == 'retired']), data[data['job'] == 'retired'].y.value_counts()[1]/len(data[data['job'] == 'retired'])])\n",
    "table.add_row(['Self-employed', len(data[data['job'] == 'self-employed']), data[data['job'] == 'self-employed'].y.value_counts()[1]/len(data[data['job'] == 'self-employed'])])\n",
    "table.add_row(['Entrepreneur', len(data[data['job'] == 'entrepreneur']), data[data['job'] == 'entrepreneur'].y.value_counts()[1]/len(data[data['job'] == 'entrepreneur'])])\n",
    "table.add_row(['Unemployed', len(data[data['job'] == 'unemployed']), data[data['job'] == 'unemployed'].y.value_counts()[1]/len(data[data['job'] == 'unemployed'])])\n",
    "table.add_row(['Housemaid', len(data[data['job'] == 'housemaid']), data[data['job'] == 'housemaid'].y.value_counts()[1]/len(data[data['job'] == 'housemaid'])])\n",
    "table.add_row(['Student', len(data[data['job'] == 'student']), data[data['job'] == 'student'].y.value_counts()[1]/len(data[data['job'] == 'student'])])\n",
    "table.add_row(['Unknown', len(data[data['job'] == 'unknown']), data[data['job'] == 'unknown'].y.value_counts()[1]/len(data[data['job'] == 'unknown'])])\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21892ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.poutcome.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71b654d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=data['poutcome'], data=data, hue=data['y'])\n",
    "plt.title('Count Plot of poutcome for target variable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc97a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.education.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba1b14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=data['education'], data=data, hue=data['y'])\n",
    "plt.title('Count plot of education for target variable y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b44fac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.default.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769f2f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=data['default'], data=data, hue=data['y'])\n",
    "plt.title('Count plot of default for target variable y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a40f934",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['default'] == 'yes'].y.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab5d045",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loan.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3b458b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=data['loan'], data=data, hue=data['y'])\n",
    "plt.title('Count plot of loan for target variable y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1fa96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.contact.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb2252d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=data['contact'], data=data, hue=data['y'])\n",
    "plt.title('Count plot of contact for target variable y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a860cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.month.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6f7a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=data['month'], data=data, hue=data['y'])\n",
    "plt.title('Count plot of month for target variable y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a1f601",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['month'] == 'jan'].y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613a8084",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Success rate and total clients contacted for different months:')\n",
    "print('Clients contacted in January: {}, Success rate: {}'.format(len(data[data['month'] == 'jan']), data[data['month'] == 'jan'].y.value_counts()[1]/len(data[data['month'] == 'jan'])))\n",
    "print('Clients contacted in February: {}, Success rate: {}'.format(len(data[data['month'] == 'feb']), data[data['month'] == 'feb'].y.value_counts()[1]/len(data[data['month'] == 'feb'])))\n",
    "print('Clients contacted in March: {}, Success rate: {}'.format(len(data[data['month'] == 'mar']), data[data['month'] == 'mar'].y.value_counts()[1]/len(data[data['month'] == 'mar'])))\n",
    "print('Clients contacted in April: {}, Success rate: {}'.format(len(data[data['month'] == 'apr']), data[data['month'] == 'apr'].y.value_counts()[1]/len(data[data['month'] == 'apr'])))\n",
    "print('Clients contacted in May: {}, Success rate: {}'.format(len(data[data['month'] == 'may']), data[data['month'] == 'may'].y.value_counts()[1]/len(data[data['month'] == 'may'])))\n",
    "print('Clients contacted in June: {}, Success rate: {}'.format(len(data[data['month'] == 'jun']), data[data['month'] == 'jun'].y.value_counts()[1]/len(data[data['month'] == 'jun'])))\n",
    "print('Clients contacted in July: {}, Success rate: {}'.format(len(data[data['month'] == 'jul']), data[data['month'] == 'jul'].y.value_counts()[1]/len(data[data['month'] == 'jul'])))\n",
    "print('Clients contacted in August: {}, Success rate: {}'.format(len(data[data['month'] == 'aug']), data[data['month'] == 'aug'].y.value_counts()[1]/len(data[data['month'] == 'aug'])))\n",
    "print('Clients contacted in September: {}, Success rate: {}'.format(len(data[data['month'] == 'sep']), data[data['month'] == 'sep'].y.value_counts()[1]/len(data[data['month'] == 'sep'])))\n",
    "print('Clients contacted in October: {}, Success rate: {}'.format(len(data[data['month'] == 'oct']), data[data['month'] == 'oct'].y.value_counts()[1]/len(data[data['month'] == 'oct'])))\n",
    "print('Clients contacted in November: {}, Success rate: {}'.format(len(data[data['month'] == 'nov']), data[data['month'] == 'nov'].y.value_counts()[1]/len(data[data['month'] == 'nov'])))\n",
    "print('Clients contacted in December: {}, Success rate: {}'.format(len(data[data['month'] == 'dec']), data[data['month'] == 'dec'].y.value_counts()[1]/len(data[data['month'] == 'dec'])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f12d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.drop('age_group', axis=1, inplace=True)\n",
    "sns.pairplot(data, hue='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b5e4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_data = data[numerical + ['y']]\n",
    "corr = corr_data.corr()\n",
    "plt.close()\n",
    "cor_plot = sns.heatmap(corr,annot=True,cmap='RdYlGn',linewidths=0.2,annot_kws={'size':10})\n",
    "fig=plt.gcf()\n",
    "fig.set_size_inches(12,10)\n",
    "plt.xticks(fontsize=10,rotation=-30)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb43aaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating new data frame of numerical columns \n",
    "data_numerical = data[numerical]\n",
    "print('Shape of numerical dataframe {}'.format(data_numerical.shape))\n",
    "data_numerical.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fb89c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "q3 = data_numerical.quantile(0.75)\n",
    "q1 = data_numerical.quantile(0.25)\n",
    "iqr = q3 - q1\n",
    "print('IQR for numerical attributes')\n",
    "print(iqr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3e5603",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_out = data[~((data_numerical < (q1 - 1.5 * iqr)) |(data_numerical > (q3 + 1.5 * iqr))).any(axis=1)]\n",
    "print('{} points are outliers based on IQR'.format(data.shape[0] - data_out.shape[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa0a708",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1f47d05c",
   "metadata": {},
   "source": [
    "Preprocessing\n",
    "\n",
    "Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45a257e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.replace(to_replace={'y':'yes'}, value=1, inplace=True)\n",
    "data.replace(to_replace={'y':'no'}, value=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24816a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the columns into categorical variables\n",
    "data1 = data.copy()\n",
    "data1['job'] = data1['job'].astype('category').cat.codes\n",
    "data1['marital'] = data1['marital'].astype('category').cat.codes\n",
    "data1['education'] = data1['education'].astype('category').cat.codes\n",
    "data1['contact'] = data1['contact'].astype('category').cat.codes\n",
    "data1['poutcome'] = data1['poutcome'].astype('category').cat.codes\n",
    "data1['month'] = data1['month'].astype('category').cat.codes\n",
    "data1['default'] = data1['default'].astype('category').cat.codes\n",
    "data1['loan'] = data1['loan'].astype('category').cat.codes\n",
    "data1['housing'] = data1['housing'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b7272d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['y']\n",
    "x_train, x_test, y_train, y_test = train_test_split(data.drop(['y'], axis=1), y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e793fde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train data shape {} {}'.format(x_train.shape, y_train.shape))\n",
    "print('Test data shape {} {}'.format(x_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500ca482",
   "metadata": {},
   "source": [
    "# feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a225f6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-white')\n",
    "\n",
    "clf = DecisionTreeClassifier(class_weight='balanced', min_weight_fraction_leaf = 0.01)\n",
    "\n",
    "clf.fit(x_train, y_train)\n",
    "importances = clf.feature_importances_\n",
    "feature_names = data.drop('y', axis=1).columns\n",
    "indices = np.argsort(importances)\n",
    "\n",
    "def feature_importance_graph(indices, importances, feature_names):\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.title(\"Feature Importance\", fontsize=10)\n",
    "    plt.barh(range(len(indices)), importances[indices], color='g',  align=\"center\")\n",
    "    plt.yticks(range(len(indices)), feature_names[indices], rotation='horizontal',fontsize=14)\n",
    "    plt.ylim([-1, len(indices)])\n",
    "    \n",
    "feature_importance_graph(indices, importances, feature_names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2c1119",
   "metadata": {},
   "outputs": [],
   "source": [
    "Encoding data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136d9039",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(vocabulary=x_train.poutcome.unique())\n",
    "x_train_poutcome = vectorizer.fit_transform(x_train.poutcome)\n",
    "x_test_poutcome = vectorizer.transform(x_test.poutcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce92496",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(vocabulary=x_train.contact.unique())\n",
    "x_train_contact = vectorizer.fit_transform(x_train.contact)\n",
    "x_test_contact = vectorizer.transform(x_test.contact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e937989",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(vocabulary=x_train.month.unique())\n",
    "x_train_month = vectorizer.fit_transform(x_train.month)\n",
    "x_test_month = vectorizer.transform(x_test.month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dff4fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(vocabulary=x_train.housing.unique())\n",
    "x_train_housing = vectorizer.fit_transform(x_train.housing)\n",
    "x_test_housing = vectorizer.transform(x_test.housing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8963ef",
   "metadata": {},
   "source": [
    "# Encoding Numerical data using Normalizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0ae62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = Normalizer()\n",
    "x_train_duration = vectorizer.fit_transform(x_train.duration.values.reshape(1,-1)).transpose()\n",
    "x_test_duration = vectorizer.transform(x_test.duration.values.reshape(1, -1)).transpose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8bd652",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = Normalizer()\n",
    "x_train_pdays = vectorizer.fit_transform(x_train.pdays.values.reshape(1,-1)).transpose()\n",
    "x_test_pdays = vectorizer.transform(x_test.pdays.values.reshape(1, -1)).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23dc9b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = Normalizer()\n",
    "x_train_age = vectorizer.fit_transform(x_train.age.values.reshape(1,-1)).transpose()\n",
    "x_test_age = vectorizer.transform(x_test.age.values.reshape(1, -1)).transpose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d702c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = Normalizer()\n",
    "x_train_balance = vectorizer.fit_transform(x_train.balance.values.reshape(1,-1)).transpose()\n",
    "x_test_balance = vectorizer.transform(x_test.balance.values.reshape(1, -1)).transpose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97885075",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack\n",
    "\n",
    "train = hstack((x_train_contact, x_train_poutcome, x_train_month, x_train_housing, x_train_duration, x_train_pdays, x_train_age, x_train_balance)).tocsr()\n",
    "\n",
    "test = hstack((x_test_contact, x_test_poutcome, x_test_month, x_test_housing, x_test_duration, x_test_pdays, x_test_age, x_test_balance)).tocsr()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b81dd9f",
   "metadata": {},
   "source": [
    "# Machine Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2c19a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary to store accuracy and roc score for each model\n",
    "score = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e4b996",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'C':[(10**i)*x for i in range(-4, 1) for x in [1,3,5]]}\n",
    "\n",
    "model = LogisticRegression(class_weight='balanced')\n",
    "clf = RandomizedSearchCV(model, parameters, cv=5, scoring='roc_auc', return_train_score=True, n_jobs=-1)\n",
    "clf.fit(train, y_train)\n",
    "print('Best parameters:  {}'.format(clf.best_params_))\n",
    "print('Best score: {}'.format(clf.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d872f068",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "\n",
    "model = LogisticRegression(C=3, class_weight='balanced', n_jobs=-1)\n",
    "model.fit(train, y_train)\n",
    "y_probs_train = model.predict_proba(train)\n",
    "y_probs_test = model.predict_proba(test)\n",
    "y_predicted_train = model.predict(train)\n",
    "y_predicted_test = model.predict(test)\n",
    "\n",
    "# keep probabilities for the positive outcome only\n",
    "y_probs_train = y_probs_train[:, 1]\n",
    "y_probs_test = y_probs_test[:, 1]\n",
    "\n",
    "# calculate AUC and Accuracy\n",
    "train_auc = roc_auc_score(y_train, y_probs_train)\n",
    "test_auc = roc_auc_score(y_test, y_probs_test)\n",
    "train_acc = accuracy_score(y_train, y_predicted_train)\n",
    "test_acc = accuracy_score(y_test, y_predicted_test)\n",
    "print('*'*50)\n",
    "print('Train AUC: %.3f' % train_auc)\n",
    "print('Test AUC: %.3f' % test_auc)\n",
    "print('*'*50)\n",
    "print('Train Accuracy: %.3f' % train_acc)\n",
    "print('Test Accuracy: %.3f' % test_acc)\n",
    "\n",
    "score['Logistic Regression'] = [test_auc, test_acc]\n",
    "\n",
    "# calculate roc curve\n",
    "train_fpr, train_tpr, train_thresholds = roc_curve(y_train, y_probs_train)\n",
    "test_fpr, test_tpr, test_thresholds = roc_curve(y_test, y_probs_test)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "# plot the roc curve for the model\n",
    "plt.plot(train_fpr, train_tpr, marker='.', label='Train AUC')\n",
    "plt.plot(test_fpr, test_tpr, marker='.', label='Test AUC')\n",
    "plt.legend()\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6fa58f64",
   "metadata": {},
   "source": [
    "Train confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01528b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cma = confusion_matrix(y_train, y_predicted_train)\n",
    "print('Confusion matrix:\\n', cma)\n",
    "df_cm = pd.DataFrame(cma, range(2), columns=range(2))\n",
    "plt.figure(figsize = (10,7))\n",
    "sns.heatmap(df_cm, annot=True,annot_kws={\"size\": 16}, fmt='g')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "824f2eeb",
   "metadata": {},
   "source": [
    "Test confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd8068a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cma = confusion_matrix(y_test, y_predicted_test)\n",
    "print('Confusion matrix:\\n', cma)\n",
    "df_cm = pd.DataFrame(cma, range(2), columns=range(2))\n",
    "plt.figure(figsize = (10,7))\n",
    "sns.heatmap(df_cm, annot=True,annot_kws={\"size\": 16}, fmt='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4961ab5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n_estimators':[75, 100, 250, 500], 'max_depth':[3, 5, 10, 15, 25]}\n",
    "model = RandomForestClassifier(class_weight='balanced', n_jobs=-1)\n",
    "clf = RandomizedSearchCV(model, param_distributions=params, cv=5, scoring='roc_auc', random_state=42, n_jobs=-1, return_train_score=True)\n",
    "clf.fit(train, y_train)\n",
    "print('Best parameters:  {}'.format(clf.best_params_))\n",
    "print('Best score: {}'.format(clf.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8ee2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=250, max_depth=25, class_weight='balanced', n_jobs=-1)\n",
    "model.fit(train, y_train)\n",
    "y_probs_train = model.predict_proba(train)\n",
    "y_probs_test = model.predict_proba(test)\n",
    "y_predicted_train = model.predict(train)\n",
    "y_predicted_test = model.predict(test)\n",
    "\n",
    "# keep probabilities for the positive outcome only\n",
    "y_probs_train = y_probs_train[:, 1]\n",
    "y_probs_test = y_probs_test[:, 1]\n",
    "\n",
    "# calculate AUC and Accuracy\n",
    "train_auc = roc_auc_score(y_train, y_probs_train)\n",
    "test_auc = roc_auc_score(y_test, y_probs_test)\n",
    "train_acc = accuracy_score(y_train, y_predicted_train)\n",
    "test_acc = accuracy_score(y_test, y_predicted_test)\n",
    "print('*'*50)\n",
    "print('Train AUC: %.3f' % train_auc)\n",
    "print('Test AUC: %.3f' % test_auc)\n",
    "print('*'*50)\n",
    "print('Train Accuracy: %.3f' % train_acc)\n",
    "print('Test Accuracy: %.3f' % test_acc)\n",
    "\n",
    "score['Random Forest'] = [test_auc, test_acc]\n",
    "\n",
    "# calculate roc curve\n",
    "train_fpr, train_tpr, train_thresholds = roc_curve(y_train, y_probs_train)\n",
    "test_fpr, test_tpr, test_thresholds = roc_curve(y_test, y_probs_test)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "# plot the roc curve for the model\n",
    "plt.plot(train_fpr, train_tpr, marker='.', label='Train AUC')\n",
    "plt.plot(test_fpr, test_tpr, marker='.', label='Test AUC')\n",
    "plt.legend()\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d4458b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cma = confusion_matrix(y_train, y_predicted_train)\n",
    "print('Confusion matrix:\\n', cma)\n",
    "df_cm = pd.DataFrame(cma, range(2), columns=range(2))\n",
    "plt.figure(figsize = (10,7))\n",
    "sns.heatmap(df_cm, annot=True,annot_kws={\"size\": 16}, fmt='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab321ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cma = confusion_matrix(y_test, y_predicted_test)\n",
    "print('Confusion matrix:\\n', cma)\n",
    "df_cm = pd.DataFrame(cma, range(2), columns=range(2))\n",
    "plt.figure(figsize = (10,7))\n",
    "sns.heatmap(df_cm, annot=True,annot_kws={\"size\": 16}, fmt='g')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb85959",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36fa957",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'alpha': [10**i for i in range(-4, 5)]}\n",
    "\n",
    "model = SGDClassifier(class_weight='balanced', n_jobs=-1)\n",
    "clf = RandomizedSearchCV(model, param_distributions=params, cv=5, scoring='roc_auc', random_state=42, n_jobs=-1, return_train_score=True)\n",
    "clf.fit(train, y_train)\n",
    "print('Best parameters:  {}'.format(clf.best_params_))\n",
    "print('Best score: {}'.format(clf.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cff6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SGDClassifier(alpha=0.0001, class_weight='balanced', n_jobs=-1)\n",
    "model.fit(train, y_train)\n",
    "y_probs_train = model.decision_function(train)\n",
    "y_probs_test = model.decision_function(test)\n",
    "y_predicted_train = model.predict(train)\n",
    "y_predicted_test = model.predict(test)\n",
    "\n",
    "# calculate AUC and Accuracy\n",
    "train_auc = roc_auc_score(y_train, y_probs_train)\n",
    "test_auc = roc_auc_score(y_test, y_probs_test)\n",
    "train_acc = accuracy_score(y_train, y_predicted_train)\n",
    "test_acc = accuracy_score(y_test, y_predicted_test)\n",
    "print('*'*50)\n",
    "print('Train AUC: %.3f' % train_auc)\n",
    "print('Test AUC: %.3f' % test_auc)\n",
    "print('*'*50)\n",
    "print('Train Accuracy: %.3f' % train_acc)\n",
    "print('Test Accuracy: %.3f' % test_acc)\n",
    "\n",
    "score['SVM'] = [test_auc, test_acc]\n",
    "\n",
    "# calculate roc curve\n",
    "train_fpr, train_tpr, train_thresholds = roc_curve(y_train, y_probs_train)\n",
    "test_fpr, test_tpr, test_thresholds = roc_curve(y_test, y_probs_test)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "# plot the roc curve for the model\n",
    "plt.plot(train_fpr, train_tpr, marker='.', label='Train AUC')\n",
    "plt.plot(test_fpr, test_tpr, marker='.', label='Test AUC')\n",
    "plt.legend()\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f7bc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cma = confusion_matrix(y_train, y_predicted_train)\n",
    "print('Confusion matrix:\\n', cma)\n",
    "df_cm = pd.DataFrame(cma, range(2), columns=range(2))\n",
    "plt.figure(figsize = (10,7))\n",
    "sns.heatmap(df_cm, annot=True,annot_kws={\"size\": 16}, fmt='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f867e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cma = confusion_matrix(y_test, y_predicted_test)\n",
    "print('Confusion matrix:\\n', cma)\n",
    "df_cm = pd.DataFrame(cma, range(2), columns=range(2))\n",
    "plt.figure(figsize = (10,7))\n",
    "sns.heatmap(df_cm, annot=True,annot_kws={\"size\": 16}, fmt='g')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4cb037e",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37f4f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "params = {'max_depth': [5, 10, 15], 'n_estimators': [10, 100, 500]}\n",
    "\n",
    "model = XGBClassifier(class_weight='balanced', n_jobs=-1)\n",
    "clf = RandomizedSearchCV(model, param_distributions=params, cv=5, scoring='roc_auc', random_state=42, n_jobs=-1, return_train_score=True)\n",
    "clf.fit(train, y_train)\n",
    "print('Best parameters:  {}'.format(clf.best_params_))\n",
    "print('Best score: {}'.format(clf.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882bfaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "model = XGBClassifier(max_depth=5, n_estimators=100 ,class_weight='balanced', n_jobs=-1)\n",
    "model.fit(train, y_train)\n",
    "y_probs_train = model.predict_proba(train)\n",
    "y_probs_test = model.predict_proba(test)\n",
    "y_predicted_train = model.predict(train)\n",
    "y_predicted_test = model.predict(test)\n",
    "\n",
    "# keep probabilities for the positive outcome only\n",
    "y_probs_train = y_probs_train[:, 1]\n",
    "y_probs_test = y_probs_test[:, 1]\n",
    "\n",
    "# calculate AUC and Accuracy\n",
    "train_auc = roc_auc_score(y_train, y_probs_train)\n",
    "test_auc = roc_auc_score(y_test, y_probs_test)\n",
    "train_acc = accuracy_score(y_train, y_predicted_train)\n",
    "test_acc = accuracy_score(y_test, y_predicted_test)\n",
    "print('*'*50)\n",
    "print('Train AUC: %.3f' % train_auc)\n",
    "print('Test AUC: %.3f' % test_auc)\n",
    "print('*'*50)\n",
    "print('Train Accuracy: %.3f' % train_acc)\n",
    "print('Test Accuracy: %.3f' % test_acc)\n",
    "\n",
    "score['XGBoost'] = [test_auc, test_acc]\n",
    "\n",
    "# calculate roc curve\n",
    "train_fpr, train_tpr, train_thresholds = roc_curve(y_train, y_probs_train)\n",
    "test_fpr, test_tpr, test_thresholds = roc_curve(y_test, y_probs_test)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "# plot the roc curve for the model\n",
    "plt.plot(train_fpr, train_tpr, marker='.', label='Train AUC')\n",
    "plt.plot(test_fpr, test_tpr, marker='.', label='Test AUC')\n",
    "plt.legend()\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8678540",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cma = confusion_matrix(y_train, y_predicted_train)\n",
    "print('Confusion matrix:\\n', cma)\n",
    "df_cm = pd.DataFrame(cma, range(2), columns=range(2))\n",
    "plt.figure(figsize = (10,7))\n",
    "sns.heatmap(df_cm, annot=True,annot_kws={\"size\": 16}, fmt='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb4c649",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cma = confusion_matrix(y_test, y_predicted_test)\n",
    "print('Confusion matrix:\\n', cma)\n",
    "df_cm = pd.DataFrame(cma, range(2), columns=range(2))\n",
    "plt.figure(figsize = (10,7))\n",
    "sns.heatmap(df_cm, annot=True,annot_kws={\"size\": 16}, fmt='g')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fdfd7af",
   "metadata": {},
   "source": [
    "# Stacking Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159ad476",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "\n",
    "model_1 = LogisticRegression(C=3, class_weight='balanced', n_jobs=-1)\n",
    "model_1.fit(train, y_train)\n",
    "clf_1 = CalibratedClassifierCV(model_1, method='sigmoid')\n",
    "\n",
    "model_2 = RandomForestClassifier(n_estimators=250, max_depth=25, class_weight='balanced', n_jobs=-1)\n",
    "model_2.fit(train, y_train)\n",
    "clf_2 = CalibratedClassifierCV(model_2, method='sigmoid')\n",
    "\n",
    "model_3 = SGDClassifier(alpha=0.0001, class_weight='balanced', n_jobs=-1)\n",
    "model_3.fit(train, y_train)\n",
    "clf_3 = CalibratedClassifierCV(model_3, method='sigmoid')\n",
    "\n",
    "model_4 = XGBClassifier(max_depth=5, n_estimators=100 ,class_weight='balanced', n_jobs=-1)\n",
    "model_4.fit(train, y_train)\n",
    "clf_4 = CalibratedClassifierCV(model_4, method='sigmoid')\n",
    "\n",
    "C = [0.0001,0.001,0.01,0.1,1,10]\n",
    "roc = 0\n",
    "best_C = 0\n",
    "for i in C:\n",
    "    log_reg = LogisticRegression(C=i, n_jobs=-1)\n",
    "    model = StackingClassifier(classifiers=[clf_1, clf_2, clf_3, clf_4], meta_classifier=log_reg, use_probas=True)\n",
    "    model.fit(train, y_train)\n",
    "    model_roc = roc_auc_score(y_test, model.predict_proba(test)[:, 1])\n",
    "    if roc < model_roc:\n",
    "        roc = model_roc\n",
    "        best_C = i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff8434e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.classifier import StackingClassifier\n",
    "\n",
    "log_reg = LogisticRegression(C=0.0001, n_jobs=-1)\n",
    "stack_clf = StackingClassifier(classifiers=[clf_1, clf_2, clf_3, clf_4], meta_classifier=log_reg, use_probas=True)\n",
    "stack_clf.fit(train, y_train)\n",
    "\n",
    "y_probs_train = stack_clf.predict_proba(train)\n",
    "y_probs_test = stack_clf.predict_proba(test)\n",
    "y_predicted_train = stack_clf.predict(train)\n",
    "y_predicted_test = stack_clf.predict(test)\n",
    "\n",
    "# keep probabilities for the positive outcome only\n",
    "y_probs_train = y_probs_train[:, 1]\n",
    "y_probs_test = y_probs_test[:, 1]\n",
    "\n",
    "# calculate AUC and Accuracy\n",
    "train_auc = roc_auc_score(y_train, y_probs_train)\n",
    "test_auc = roc_auc_score(y_test, y_probs_test)\n",
    "train_acc = accuracy_score(y_train, y_predicted_train)\n",
    "test_acc = accuracy_score(y_test, y_predicted_test)\n",
    "print('*'*50)\n",
    "print('Train AUC: %.3f' % train_auc)\n",
    "print('Test AUC: %.3f' % test_auc)\n",
    "print('*'*50)\n",
    "print('Train Accuracy: %.3f' % train_acc)\n",
    "print('Test Accuracy: %.3f' % test_acc)\n",
    "\n",
    "score['Stacking Classifier'] = [test_auc, test_acc]\n",
    "\n",
    "# calculate roc curve\n",
    "train_fpr, train_tpr, train_thresholds = roc_curve(y_train, y_probs_train)\n",
    "test_fpr, test_tpr, test_thresholds = roc_curve(y_test, y_probs_test)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "# plot the roc curve for the stack_clf\n",
    "plt.plot(train_fpr, train_tpr, marker='.', label='Train AUC')\n",
    "plt.plot(test_fpr, test_tpr, marker='.', label='Test AUC')\n",
    "plt.legend()\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44eec42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cma = confusion_matrix(y_train, y_predicted_train)\n",
    "print('Confusion matrix:\\n', cma)\n",
    "df_cm = pd.DataFrame(cma, range(2), columns=range(2))\n",
    "plt.figure(figsize = (10,7))\n",
    "sns.heatmap(df_cm, annot=True,annot_kws={\"size\": 16}, fmt='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e300ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cma = confusion_matrix(y_test, y_predicted_test)\n",
    "print('Confusion matrix:\\n', cma)\n",
    "df_cm = pd.DataFrame(cma, range(2), columns=range(2))\n",
    "plt.figure(figsize = (10,7))\n",
    "sns.heatmap(df_cm, annot=True,annot_kws={\"size\": 16}, fmt='g')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cd0e13",
   "metadata": {},
   "source": [
    "# Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0febcd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "model = VotingClassifier(estimators=[('log_reg', clf_1), ('rf', model_2), ('stack', stack_clf), ('xgb', model_4), ('log_reg_1', model_1)], voting='soft')\n",
    "model.fit(train, y_train)\n",
    "\n",
    "y_probs_train = model.predict_proba(train)\n",
    "y_probs_test = model.predict_proba(test)\n",
    "y_predicted_train = model.predict(train)\n",
    "y_predicted_test = model.predict(test)\n",
    "\n",
    "# keep probabilities for the positive outcome only\n",
    "y_probs_train = y_probs_train[:, 1]\n",
    "y_probs_test = y_probs_test[:, 1]\n",
    "\n",
    "# calculate AUC and Accuracy\n",
    "train_auc = roc_auc_score(y_train, y_probs_train)\n",
    "test_auc = roc_auc_score(y_test, y_probs_test)\n",
    "train_acc = accuracy_score(y_train, y_predicted_train)\n",
    "test_acc = accuracy_score(y_test, y_predicted_test)\n",
    "print('*'*50)\n",
    "print('Train AUC: %.3f' % train_auc)\n",
    "print('Test AUC: %.3f' % test_auc)\n",
    "print('*'*50)\n",
    "print('Train Accuracy: %.3f' % train_acc)\n",
    "print('Test Accuracy: %.3f' % test_acc)\n",
    "\n",
    "score['Voting Classifier'] = [test_auc, test_acc]\n",
    "\n",
    "# calculate roc curve\n",
    "train_fpr, train_tpr, train_thresholds = roc_curve(y_train, y_probs_train)\n",
    "test_fpr, test_tpr, test_thresholds = roc_curve(y_test, y_probs_test)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "# plot the roc curve for the model\n",
    "plt.plot(train_fpr, train_tpr, marker='.', label='Train AUC')\n",
    "plt.plot(test_fpr, test_tpr, marker='.', label='Test AUC')\n",
    "plt.legend()\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5289d040",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cma = confusion_matrix(y_train, y_predicted_train)\n",
    "print('Confusion matrix:\\n', cma)\n",
    "df_cm = pd.DataFrame(cma, range(2), columns=range(2))\n",
    "plt.figure(figsize = (10,7))\n",
    "sns.heatmap(df_cm, annot=True,annot_kws={\"size\": 16}, fmt='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c527e1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cma = confusion_matrix(y_test, y_predicted_test)\n",
    "print('Confusion matrix:\\n', cma)\n",
    "df_cm = pd.DataFrame(cma, range(2), columns=range(2))\n",
    "plt.figure(figsize = (10,7))\n",
    "sns.heatmap(df_cm, annot=True,annot_kws={\"size\": 16}, fmt='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc5daf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('***************  Comparison of different models  ****************')\n",
    "table = PrettyTable(['Model', 'Test AUC', 'Test Accuracy'])\n",
    "for item in score.items():\n",
    "    table.add_row([item[0], item[1][0], item[1][1]])\n",
    "print(table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
